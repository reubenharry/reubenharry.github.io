{
    "version" : "https://jsonfeed.org/version/1",
    "title" : "Reuben Cohn-Gordon",
    "description": "Recent content on Reuben Cohn-Gordon",
    "home_page_url" : "https://reubenharry.github.io",
    "feed_url" : "https://reubenharry.github.io/index.json",
    "icon" : "https://reubenharry.github.io/apple-touch-icon-180.png",
    "favicon" : "https://reubenharry.github.io/icon-64.png",
    "author" : {
        "name" : "Reuben Cohn-Gordon",
        "url": "https://reubenharry.github.io",
        "avatar": "https://reubenharry.github.io/static/img/profile.png"
    },
    "items" : [
    {
        "title" : "Research",
        "date_published" : "2018-06-26T17:07:24+01:00",
        "date_modified" : "2018-06-26T17:07:24+01:00",
        "id" : "https://reubenharry.github.io/research/",
        "url" : "https://reubenharry.github.io/research/",
        "author" : {
          "name" : "Reuben Cohn-Gordon"
        },
        "content_html" : "\n\n\u003cp\u003eMy current work centers around \u003ca href=\"https://reubenharry.github.io/blog/social-reasoning-in-arcadia/\"\u003eBayesian models of pragmatics\u003c/a\u003e. I\u0026rsquo;m interested in extending them to figurative language (particularly irony and metaphor) and sociolinguistic phenomena (indexicality), as well as scaling them in computationally tractable ways to handle the complexity of natural language.\u003c/p\u003e\n\n\u003ch3 id=\"computational-pragmatics\"\u003eComputational Pragmatics\u003c/h3\u003e\n\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/1902.09514\"\u003eLost in Machine Translation: A Method to Reduce Meaning Loss\u003c/a\u003e \u003cbr/\u003e (NAACL 2019 - Cohn-Gordon and Goodman)\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/1804.05417\"\u003ePragmatically Informative Image Captioning with Character-Level Inference\u003c/a\u003e (\u003ca href=\"/docs/naacl_slides.pdf\"\u003eslides\u003c/a\u003e) \u003cbr/\u003e (NAACL 2018 - Cohn-Gordon, Goodman and Potts)\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/1810.00367\"\u003eAn Incremental Iterated Response Model of Pragmatics\u003c/a\u003e \u003cbr/\u003e (SCiL 2019, ACL Proceedings - Cohn-Gordon, Goodman and Potts) \u003cbr\u003e\n(Similar work presented at CompPrag 2018 - Cohn-Gordon and Potts)\u003c/p\u003e\n\n\u003ch3 id=\"social-meaning\"\u003eSocial Meaning\u003c/h3\u003e\n\n\u003cp\u003e\u003ca href=\"/docs/socialmet.pdf\"\u003eModeling \u0026ldquo;Non-literal\u0026rdquo; Social Meaning with Bayesian Pragmatics\u003c/a\u003e (\u003ca href=\"/docs/sub_slides.pdf\"\u003eslides\u003c/a\u003e) \u003cbr/\u003e(Sinn und Bedeutung 2018 - Cohn-Gordon and Qing)\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"/docs/usecond.pdf\"\u003eNon-descriptive/use-conditional meaning in Rational Speech-Act models\u003c/a\u003e \u003cbr/\u003e (Sinn und Bedeutung 2018 - Qing and Cohn-Gordon)\u003c/p\u003e\n\n\u003ch3 id=\"past-work\"\u003ePast Work\u003c/h3\u003e\n\n\u003cp\u003e\u003ca href=\"/docs/amharic.pdf\"\u003eIntransitive Object Marking in Amharic\u003c/a\u003e (\u003ca href=\"/docs/dares-and-warnings-in-amharic/\"\u003edescription\u003c/a\u003e) \u003cbr/\u003e (Presented as a \u003ca href=\"/docs/amharicposter.pdf\"\u003eposter\u003c/a\u003e at LSA 2017)\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"/docs/modals.pdf\"\u003eAbility Modals\u003c/a\u003e (\u003ca href=\"/docs/ability-modals/\"\u003edescription\u003c/a\u003e)\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"/docs/monads.pdf\"\u003eMonads for NL Semantics\u003c/a\u003e (draft)\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"/docs/resultatives.pdf\"\u003eResultativity in Latin\u003c/a\u003e (\u003ca href=\"/docs/resultativity-in-latin/\"\u003edescription\u003c/a\u003e)\u003c/p\u003e\n"
    },
    {
        "title" : "Social Reasoning in Arcadia",
        "date_published" : "2018-06-26T17:07:24+01:00",
        "date_modified" : "2018-06-26T17:07:24+01:00",
        "id" : "https://reubenharry.github.io/blog/social-reasoning-in-arcadia/",
        "url" : "https://reubenharry.github.io/blog/social-reasoning-in-arcadia/",
        "content_html" : "\n\n\u003cscript type=\"text/javascript\" async\n  src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML\"\u003e\n\u003c/script\u003e\n\n\u003cscript type=\"text/javascript\"\n  src=\"/webppl.js\"\u003e\n\u003c/script\u003e\n\n\u003cscript type=\"text/javascript\"\n  src=\"/webppl-editor.js\"\u003e\n\u003c/script\u003e\n\n\u003cscript type=\"text/javascript\"\n  src=\"/webppl-viz.js\"\u003e\n\u003c/script\u003e\n\n\u003cp\u003e\u003clink rel=\"stylesheet\" href='/webppl-editor.css'\u003e\u003c/p\u003e\n\n\u003cp\u003e\u003clink rel=\"stylesheet\" href='/webppl-viz.css'\u003e\u003c/p\u003e\n\n\u003ch3 id=\"a-tour-of-the-bayesian-perspective-on-pragmatics\"\u003eA tour of the Bayesian perspective on pragmatics\u003c/h3\u003e\n\n\u003cp\u003eThis is an introduction to the nested reasoning models (\u003cem\u003eI think that you think that I think\u0026hellip;\u003c/em\u003e) that I work on. I\u0026rsquo;ve tried to make this light on mathematical detail (barring the occasional technical digression) in favour of the big picture point, that Bayesian inference and nested reasoning are really great tools for thinking about language and meaning.\u003c/p\u003e\n\n\u003chr /\u003e\n\n\u003cp\u003ePicture the scene: it\u0026rsquo;s midday in Arcadia and Echo is waiting for Narcissus to finish his lengthy beauty routine:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eEcho: Will you be done soon?\u003c/p\u003e\n\n\u003cp\u003eNarcissus: Don\u0026rsquo;t hold your breath.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eWe gather from Narcissus\u0026rsquo; response that the answer is no, but how? After all, if Echo had asked \u0026ldquo;what is a useful piece of advice when deep sea diving\u0026rdquo;, Narcissus\u0026rsquo; reply would take on a totally different character. So it would seem that the meaning we infer from Narcissus\u0026rsquo; utterance depends not only on the utterance itself, but the context in which it is said.\u003c/p\u003e\n\n\u003cp\u003eMeaning, to understate the issue, is a bit of a head scratcher. We could venture to say that Narcissus\u0026rsquo; statement has \u003cstrong\u003esemantic\u003c/strong\u003e content (it\u0026rsquo;s a recommendation to not hold your breath), and meanings in different contexts (\u0026ldquo;No I won\u0026rsquo;t be ready any time soon.\u0026rdquo;, \u0026ldquo;Holding your breath is a poor way to dive.\u0026rdquo;), which is \u003cem\u003einferred\u003c/em\u003e from the context. (Deciding what content belongs to the statement as opposed to the context is often tricky. For instance, \u0026ldquo;don\u0026rsquo;t hold your breath\u0026rdquo; is an idiom in English - the meaning \u0026ldquo;It will take a long time\u0026rdquo; is at least somewhat baked into its semantic content.)\u003c/p\u003e\n\n\u003cfigure \u003e\n\u003cimg src=\"/img/diagram2.png\"  width=\"747\" height=\"211\"\u003e\n\u003c/figure\u003e\n\n\n\u003cp\u003eThe inference to obtain this \u0026ldquo;full\u0026rdquo; meaning from the semantic content and context, which we make so easily, is complicated to spell out, even if a vague, informal way:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eif Narcissus had been able to answer truthfully that he would be done soon, he would have done, but he did not. Given that, and since \u0026ldquo;Don\u0026rsquo;t hold your breath\u0026rdquo; is relevant advice in situations where you\u0026rsquo;re going to have to wait a long time, it seems that Narcissus is trying to convey that he won\u0026rsquo;t be done soon.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThe study of the semantic content belongs to the field of \u003cem\u003esemantics\u003c/em\u003e, while the richer meaning derived from reasoning about the situation - the pragmatic content - is the focus of \u003cem\u003epragmatics\u003c/em\u003e (The distinction was described as follows by a student in a class I TA\u0026rsquo;ed: \u003cem\u003e\u0026ldquo;Semantics is about what things mean, and pragmatics is about what they like actually mean.\u0026rdquo;\u003c/em\u003e. Relatedly, I\u0026rsquo;ve always wanted to write a philosophy paper introducing a \u003cem\u003elike actually\u003c/em\u003e operator LA, such that LA(P) iff P is like actually true.). The hope is that by factoring the relation between language and the world into these two pieces, we can simplify and refine our understanding of how that relationship works.\u003c/p\u003e\n\n\u003cp\u003eI want to show how we can boil down the essence of the above reasoning, and get out a paradigm for formalizing pragmatics which involves \u003cem\u003enested inference\u003c/em\u003e: an inference about another agent\u0026rsquo;s inference. What I\u0026rsquo;ll describe is the \u003ca href=\"http://langcog.stanford.edu/papers_new/goodman-2016-tics.pdf\"\u003eRational Speech Acts (RSA)\u003c/a\u003e paradigm, and comes from \u003ca href=\"http://www.home.uni-osnabrueck.de/michfranke/Papers/Franke_PhD_thesis.pdf\"\u003eprevious work on game theory\u003c/a\u003e going back to \u003ca href=\"https://www.princeton.edu/~harman/Courses/PHI534-2012-13/Nov26/lewis-convention1.pdf\"\u003eLewis\u003c/a\u003e.\u003c/p\u003e\n\n\u003cfigure \u003e\n\u003cimg src=\"/img/nested.png\"  width=\"342\" height=\"377\"\u003e\n\u003c/figure\u003e\n\n\n\u003cp\u003eMy goal here is to show why the language of Bayesian probability (and in particular, recursive inference models like RSA) are the Right Tool for the Job: they neatly incorporate and generalize a logical semantics, can be \u003ca href=\"http://www.problang.org/\"\u003ecomputationally modeled\u003c/a\u003e, \u003ca href=\"https://psyarxiv.com/f9y6b/\"\u003eexperimentally tested\u003c/a\u003e, \u003ca href=\"https://nlp.stanford.edu/pubs/monroe2015learning.pdf\"\u003eintegrated with machine learning\u003c/a\u003e, and what for my money matters most, formalize the essence of social reasoning. In short, \u003cstrong\u003ethey are for pragmatics what classical logic is for semantics\u003c/strong\u003e.\u003c/p\u003e\n\n\u003ch1 id=\"starting-simple\"\u003eStarting Simple\u003c/h1\u003e\n\n\u003cp\u003eOK, so in the interest of tractability, let\u0026rsquo;s exchange our complex example from above for something much simpler and more mundane. Our Classical couple are looking for two sheep that have wandered off from the herd (shepherding is really the only profession in Arcadia):\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eEcho: Did you find both sheep?\u003c/p\u003e\n\n\u003cp\u003eNarcissus: I found one of them.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eThis example, or something similar, is the \u003cem\u003e\u003ca href=\"https://www.ncbi.nlm.nih.gov/pubmed/22530382\"\u003edrosophila\u003c/a\u003e\u003c/em\u003e of pragmatics: a scalar implicature. It\u0026rsquo;s like the previous example in that the semantic and pragmatic content differ; Narcissus doesn\u0026rsquo;t explicitly say that he didn\u0026rsquo;t find both of them. That\u0026rsquo;s a state of affairs compatible with his utterance. After all, if you\u0026rsquo;ve found both, it\u0026rsquo;s true that you\u0026rsquo;ve found one. A logician might represent the \u003cstrong\u003esemantic content\u003c/strong\u003e of his utterance as\u003c/p\u003e\n\n\u003cp\u003e$$ (1) \\quad \\exists s. found(N,s)$$\u003c/p\u003e\n\n\u003cp\u003eHowever, if it was true that he\u0026rsquo;d found both sheep, he would have said as much, so we can \u003cem\u003einfer\u003c/em\u003e that he found one but not both. We could represent this \u003cstrong\u003epragmatic content\u003c/strong\u003e as\u003c/p\u003e\n\n\u003cp\u003e$$(2) \\quad \\exists s. found(N,s) \\wedge \\neg\\forall s. found(N,s)$$\u003c/p\u003e\n\n\u003cp\u003eNote that (1) does not logically imply (2). That is, knowing that (1) is true is not enough in itself to know that (2) is true. And yet, we do know, or at least strongly suspect (2) is the case on the basis of Narcissus\u0026rsquo; utterance.\u003c/p\u003e\n\n\u003cp\u003eSo if we can\u0026rsquo;t get from (1) to (2) by logical means, we\u0026rsquo;ll need something else, capable of representing the counterfactual reasoning: \u0026ldquo;since (2) is a more informative statement than (1) (on account of implying (1)), if Narcissus been in a position to say (2), he would have. But he didn\u0026rsquo;t, so he wasn\u0026rsquo;t.\u0026rdquo;.\u003c/p\u003e\n\n\u003cp\u003eFortunately, this example is simple enough that we can \u003cstrong\u003eformalize\u003c/strong\u003e it - i.e. build a model (with nice interactive code) which captures everything we are presently interested in about it. So let\u0026rsquo;s.\u003c/p\u003e\n\n\u003ch1 id=\"preliminaries\"\u003ePreliminaries\u003c/h1\u003e\n\n\u003cp\u003eWe\u0026rsquo;re going to refer to the set of all utterances as \u003cstrong\u003eU\u003c/strong\u003e. \u003cstrong\u003eU\u003c/strong\u003e represents all the things Narcissus could have said as a reply to Echo\u0026rsquo;s question. Because this is a simple model, we\u0026rsquo;ll replace the infinitude of possible utterances with a more modest number, 2. \u003cstrong\u003eU\u003c/strong\u003e = { \u003cem\u003eI found one of the sheep\u003c/em\u003e, \u003cem\u003eI found both of the sheep\u003c/em\u003e}.\u003c/p\u003e\n\n\u003cp\u003eThere\u0026rsquo;s another set we need to consider, the set \u003cstrong\u003eW\u003c/strong\u003e of all possible states (i.e. things which could be the case in the world). Again, our present purposes allow us to keep this simple too\u003c/p\u003e\n\n\u003cul\u003e\n\u003cli\u003e\u003cem\u003eone\u003c/em\u003e: the state in which Narcissus has found exactly 1 sheep\u003c/li\u003e\n\u003cli\u003e\u003cem\u003etwo\u003c/em\u003e: the state in which Narcissus has found exactly 2 sheep\u003c/li\u003e\n\u003c/ul\u003e\n\n\u003cp\u003eWe\u0026rsquo;re now in a position to talk about literal meaning. In a state \u003cem\u003ew\u003c/em\u003e \\(\\in\\) \u003cstrong\u003eW\u003c/strong\u003e, an utterance is either true or false. For example, if Narcissus has found one sheep, so that the world state is \u003cem\u003eone\u003c/em\u003e, then saying \u003cem\u003eI found both of the sheep\u003c/em\u003e is untrue. He\u0026rsquo;d be deluded or deceitful to say it.\u003c/p\u003e\n\n\u003cp\u003eOK, so formally, that all means that the semantics is a \u003cstrong\u003erelation\u003c/strong\u003e, which is a function of type \\(((U,W)\\to\\{\\mathit{True},\\mathit{False}\\}\\)) (we write [u](w) to mean that the thing \u003cem\u003eu\u003c/em\u003e means is compatible with the world \u003cem\u003ew\u003c/em\u003e). More visually, a world \u003cem\u003ew\u003c/em\u003e and an utterance \u003cem\u003eu\u003c/em\u003e are related if there\u0026rsquo;s a line between them, as in the diagram below:\u003c/p\u003e\n\n\u003cfigure \u003e\n\u003cimg src=\"/img/diagram3.png\"  width=\"750\" height=\"328\"\u003e\n\u003c/figure\u003e\n\n\n\u003cp\u003eTo make things a bit more interactive, here\u0026rsquo;s some code to play with in a probabilistic programming language (\u003ca href=\"https://probmods.org/\"\u003ethis introduction\u003c/a\u003e uses PPLs to model cognition) which represents the semantics. Nothing probabilistic yet, but WebPPL will feature again below in a more sophisticated capacity.\u003c/p\u003e\n\n\u003cpre\u003e\nvar worlds = [{totalSheepFound:1},{totalSheepFound:2}]\nvar utterances = [\n    \"I found one of the sheep\",\n    \"I found both of the sheep\"]\n\nvar meaning = function(utterance, world){\n  (utterance === \"I found one of the sheep\")\n  \u0026\u0026 (world['totalSheepFound']\u003e0)  ? true :\n  (utterance === \"I found both of the sheep\")\n  \u0026\u0026 (world['totalSheepFound']==2)  ? true :\n  false}\n\nmeaning(\"I found both of the sheep\",{totalSheepFound:1})\n\n\u003c/pre\u003e\n\n\u003ch1 id=\"overview-of-the-model\"\u003eOverview of The Model\u003c/h1\u003e\n\n\u003cp\u003eAnd now for the Bayesian part. We\u0026rsquo;ll start by modeling literal interpretation, via a model I\u0026rsquo;ll call \\(L_0\\), which is hardly anything more than the semantics we already have in a slightly different shape. We\u0026rsquo;ll use \\(L_0\\) to build a model of production (i.e. choice of utterance given world state) called \\(S_1\\), which in turn we\u0026rsquo;ll use to build our end goal, \\(L_1\\). \\(L_1\\) is a model of interpretation which accounts not just for semantic meaning, but for pragmatic meaning. We can think of \\(L_1\\) as a model which reasons about a speaker \\(S_1\\) which is itself reasoning about \\(L_0\\). Sorry if that\u0026rsquo;s a bit of a mouthful. The big picture idea is that by reasoning about your interlocutor reasoning about you, you can infer extra, \u003cem\u003epragmatic\u003c/em\u003e, meaning beyond the semantic content of what you hear.\u003c/p\u003e\n\n\u003cfigure \u003e\n\u003cimg src=\"/img/diagram1.png\"  width=\"749\" height=\"387\"\u003e\n\u003c/figure\u003e\n\n\n\u003cp\u003eThis image graphically represents the overview above. On the left we have the space of utterances, and on the right, the space of worlds. Models of interpretation, often called \u0026ldquo;listeners\u0026rdquo;, are shown as red arrows (in a precise sense discussed below) from \u003cstrong\u003eU\u003c/strong\u003e to \u003cstrong\u003eW\u003c/strong\u003e, while models of production, sometimes called \u0026ldquo;speakers\u0026rdquo;, are depicted as blue arrows in the opposite direction. Finally, the vertical arrow between speaker and listener models are there to suggest that the \\(L_1\\) is build from the \\(S_1\\), and the \\(S_1\\) from the \\(L_0\\).\u003c/p\u003e\n\n\u003cp\u003e(Brief digression with technical hat on: for the computer scientists, there\u0026rsquo;s a more general recursive definition: \\( S_n \\) is defined in terms of \\( L_n\\__1 \\), which is defined in terms of \\(S_n\\__1\\), and so on. \\(L_0\\) is the base case of the recursion, and the fix point \\(L_m\\) such that \\(L_m\\) = \\(L_m\\__1\\) represents the ideal listener, which is closely related to the notion of a game theoretic equilibrium.)\u003c/p\u003e\n\n\u003ch1 id=\"the-literal-listener-l-0\"\u003eThe Literal Listener \\(L_0\\)\u003c/h1\u003e\n\n\u003cp\u003eFirst of all, what type of thing is \\(L_0\\)? It\u0026rsquo;s going to be a function which takes \u003cem\u003eu\u003c/em\u003e \\(\\in\\) \u003cem\u003eU\u003c/em\u003e and returns a distribution over all \u003cem\u003ew\u003c/em\u003e \\(\\in\\) W. This is just a way of saying it\u0026rsquo;s a conditional distribution \\(L_0\\)(w|u), but I prefer the function perspective (*\u003cem\u003eputting on the pointiest most arcane ivory tower shaped hat*\u003c/em\u003e, a conditional distribution is a morphism in a very special \u003ca href=\"https://plato.stanford.edu/entries/category-theory/#2\"\u003ecategory\u003c/a\u003e - the Kleisli category of the distribution monad - which is precisely why it makes sense to view them as arrows, and implicitly is what we\u0026rsquo;re doing when we do probabilistic programming. If you do probabilistic programming in Haskell, then it\u0026rsquo;s also explicitly what you\u0026rsquo;re doing.).\u003c/p\u003e\n\n\u003cp\u003eHere\u0026rsquo;s the (simplest possible) definition of \\(L_0\\) (I\u0026rsquo;m ignoring things like cost, non-uniform priors on worlds and utterances, rationality parameters - all useful, but unnecessary for deriving scalar implicatures):\u003c/p\u003e\n\n\u003cp\u003e$$L0(w|u) =  \\frac{[u](w)}{\\sum_{w\u0026rsquo;} [u](w\u0026rsquo;)} $$\u003c/p\u003e\n\n\u003cp\u003eIf you\u0026rsquo;re like me, this equation might seem less than helpful. Here\u0026rsquo;s an explanation of what it actually amounts to: After hearing an utterance u, \\(L_0\\) thinks all worlds \u003cem\u003ecompatible with the utterance they just heard\u003c/em\u003e are equally likely. Here\u0026rsquo;s code that implements the \\(L_0\\):\u003c/p\u003e\n\n\u003cpre\u003e\nvar worlds = [{totalSheepFound:1},{totalSheepFound:2}]\nvar utterances = [\n    \"I found one of the sheep\",\n    \"I found both of the sheep\"]\n\nvar meaning = function(utterance, world){\n  (utterance === \"I found one of the sheep\")\n  \u0026\u0026 (world['totalSheepFound']\u003e0)  ? true :\n  (utterance === \"I found both of the sheep\")\n  \u0026\u0026 (world['totalSheepFound']==2)  ? true :\n  false}\n\nvar l0 = function(utterance){\n  Infer({model: function(){\n    var world = uniformDraw(worlds);\n    condition(meaning(utterance, world))\n    return world}})}\n\nviz(l0(\"I found one of the sheep\"))\nviz(l0(\"I found both of the sheep\"))\n\n\u003c/pre\u003e\n\n\u003cp\u003eSo \\(L_0\\) is a simple generalization of a logical semantics. Probabilistic programming is useful for defining this sort of model, particularly when things start getting complicated. Oh, and here\u0026rsquo;s a visualization of the \\(L_0\\) posterior conditional distributions:\u003c/p\u003e\n\n\u003cfigure \u003e\n\u003cimg src=\"/img/diagram4.png\"  width=\"750\" height=\"373\"\u003e\n\u003c/figure\u003e\n\n\n\u003ch1 id=\"the-informative-speaker-s-1\"\u003eThe Informative Speaker \\(S_1\\)\u003c/h1\u003e\n\n\u003cp\u003eThere\u0026rsquo;s a sense in which \u003cem\u003eproduction is the dual of interpretation\u003c/em\u003e. A production model is a conditional distribution p(u|w); given a state, it gives a distribution over utterances. The particular production model we\u0026rsquo;re interested in is \\(S_1\\), defined as:\u003c/p\u003e\n\n\u003cp\u003e$$S1(u|w) = \\frac{L0(w|u)}{\\sum_{u\u0026rsquo;} L0(w|u\u0026rsquo;)}$$\u003c/p\u003e\n\n\u003cp\u003eThis production model\u0026rsquo;s goal is to maximize informativity; it has some state \u003cem\u003ew\u003c/em\u003e it wants to convey, and it put the most weight on the utterance \u003cem\u003eu\u003c/em\u003e which gets the literal listener \\(L_0\\) to place the most weight on \u003cem\u003ew\u003c/em\u003e after hearing u. Again, code, to make that interactive:\u003c/p\u003e\n\n\u003cpre\u003e\n\nvar worlds = [{totalSheepFound:1},{totalSheepFound:2}]\nvar utterances = [\n    \"I found one of the sheep\",\n    \"I found both of the sheep\"]\n\nvar meaning = function(utterance, world){\n  (utterance === \"I found one of the sheep\")\n  \u0026\u0026 (world['totalSheepFound']\u003e0)  ? true :\n  (utterance === \"I found both of the sheep\")\n  \u0026\u0026 (world['totalSheepFound']==2)  ? true :\n  false}\n\nvar l0 = function(utterance){\n  Infer({model: function(){\n    var world = uniformDraw(worlds);\n    condition(meaning(utterance, world))\n    return world}})}\n\nvar s1 = function(world){\n  Infer({model: function(){\n    var utterance = uniformDraw(utterances)\n    factor(l0(utterance).score(world))\n    return utterance}})}\n\nviz(s1({totalSheepFound:1}))\nviz(s1({totalSheepFound:2}))\n\n\u003c/pre\u003e\n\n\u003cp\u003eAnd a diagram of the conditional distributions:\u003c/p\u003e\n\n\u003cfigure \u003e\n\u003cimg src=\"/img/diagram5.png\"  width=\"750\" height=\"377\"\u003e\n\u003c/figure\u003e\n\n\n\u003ch1 id=\"the-pragmatic-listener-l-1\"\u003eThe Pragmatic Listener \\(L_1\\)\u003c/h1\u003e\n\n\u003cp\u003eOK, so we had a listener \\(L_0\\). And we had \\(S_1\\) thinking about \\(L_0\\). Now we\u0026rsquo;re going to have \\(L_1\\), which is a model of a listener who thinks about \\(S_1\\) thinking about \\(L_0\\):\u003c/p\u003e\n\n\u003cp\u003e$$L1(w|u) = \\frac{S1(u|w)}{\\sum_{w\u0026rsquo;} S1(w\u0026rsquo;|u)}$$\u003c/p\u003e\n\n\u003cp\u003eYou can think of \\(L_1\\) hearing an utterance \u003cem\u003eu\u003c/em\u003e and asking the following question: what world state must \\(S_1\\) have been in to have said u. See what happens when you run the code.\u003c/p\u003e\n\n\u003cpre\u003e\n\nvar worlds = [{totalSheepFound:1},{totalSheepFound:2}]\nvar utterances = [\n    \"I found one of the sheep\",\n    \"I found both of the sheep\"]\n\nvar meaning = function(utterance, world){\n  (utterance === \"I found one of the sheep\")\n  \u0026\u0026 (world['totalSheepFound']\u003e0)  ? true :\n  (utterance === \"I found both of the sheep\")\n  \u0026\u0026 (world['totalSheepFound']==2)  ? true :\n  false}\n\nvar l0 = function(utterance){\n  Infer({model: function(){\n    var world = uniformDraw(worlds);\n    condition(meaning(utterance, world))\n    return world}})}\n\nvar s1 = function(world){\n  Infer({model: function(){\n    var utterance = uniformDraw(utterances)\n    factor(l0(utterance).score(world))\n    return utterance}})}\n\n// pragmatic listener\nvar l1 = function(utterance){\n  Infer({model: function(){\n    var world = uniformDraw(worlds)\n    factor(s1(world).score(utterance))\n    return world }})}\n\nviz(l1(\"I found one of the sheep\"))\nviz(l1(\"I found both of the sheep\"))\n\n\u003c/pre\u003e\n\n\u003cp\u003eOr just see the figure below:\u003c/p\u003e\n\n\u003cfigure \u003e\n\u003cimg src=\"/img/diagram6.png\"  width=\"750\" height=\"376\"\u003e\n\u003c/figure\u003e\n\n\n\u003cp\u003eThe takeaway is that \\(L_1\\) hears \u003cem\u003eI found one of the sheep\u003c/em\u003e and \u003cstrong\u003einfers\u003c/strong\u003e that it\u0026rsquo;s more likely to be the case that \u003cem\u003eonly\u003c/em\u003e one sheep has been found. Tada, it\u0026rsquo;s a scalar implicature!\u003c/p\u003e\n\n\u003cp\u003eSo to wrap up, we\u0026rsquo;ve seen how to model a simple type of pragmatic meaning using nested Bayesian models. This example was simple, but the core idea of \u003cem\u003epragmatic phenomena arising naturally from a semantics and nested reasoning\u003c/em\u003e is powerful. All sorts of pragmatic phenomena can be tackled with tools of this ilk, like \u003ca href=\"https://web.stanford.edu/~danlass/Lassiter-Goodman-adjectival-vagueness-Synthese.pdf\"\u003evagueness\u003c/a\u003e, \u003ca href=\"https://mindmodeling.org/cogsci2014/papers/132/paper132.pdf\"\u003emetaphor\u003c/a\u003e,  \u003ca href=\"http://www.pnas.org/content/111/33/12002\"\u003ehyperbole\u003c/a\u003e, \u003ca href=\"https://onlinelibrary.wiley.com/doi/epdf/10.1111/tops.12144\"\u003efocus\u003c/a\u003e, \u003ca href=\"http://semprag.org/article/view/sp.9.20/pdf\"\u003em-implicature\u003c/a\u003e, \u003ca href=\"https://stuhlmueller.org/papers/qa-cogsci2015.pdf\"\u003equestions\u003c/a\u003e,  \u003ca href=\"https://pdfs.semanticscholar.org/58e0/e256b3191603513f564acec4a984b6e8f3e1.pdf\"\u003egeneric language\u003c/a\u003e and \u003ca href=\"https://stanford.edu/~mtessler/papers/YoonTessler2016-cogsci.pdf\"\u003epoliteness\u003c/a\u003e.\u003c/p\u003e\n\n\u003cp\u003eWith a logical semantics, we had a way to get from utterances to compatible world states, but no way to handle pragmatic meaning formally. By making things probabilistic, we get to do semantics and pragmatics in a unified framework: pragmatic and semantic meanings exist in the same space. That\u0026rsquo;s good.\u003c/p\u003e\n\n\u003cp\u003eMoreover, in this paradigm, pragmatic meaning arises naturally from a recursive process of inter-agent reasoning where the base case is a semantics, i.e. a conventional relationship between states of the world and utterances.\u003c/p\u003e\n\n\u003cp\u003eNext time, we\u0026rsquo;ll see that by changing \u003cem\u003eU\u003c/em\u003e and \u003cem\u003eW\u003c/em\u003e to represent different spaces, similar models take on a different character and can be used to model sociolinguistic phenomena.\u003c/p\u003e\n\n\u003ch1 id=\"faq-addendum\"\u003eFAQ Addendum:\u003c/h1\u003e\n\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eQ\u003c/strong\u003e: Why start with a literal listener, not a literal speaker? \u003cstrong\u003eA\u003c/strong\u003e: No reason - the other way works too. In fact, we could also start with both and do a mutual recursion. I\u0026rsquo;m becoming increasingly convinced that this is the right thing to do.\u003c/p\u003e\u003c/li\u003e\n\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eQ\u003c/strong\u003e: Can we add more layers above \\(L_1\\)? \u003cstrong\u003eA\u003c/strong\u003e: Yes! the more we add, the closer the model gets to making hard (i.e. non-probabilistic) decisions. See the above digression about fix points.\u003c/p\u003e\u003c/li\u003e\n\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eQ\u003c/strong\u003e: Do we ever need more? \u003cstrong\u003eA\u003c/strong\u003e: Yes. But only for more complicated phenomena. For scalar implicature, this many layers does just fine.\u003c/p\u003e\u003c/li\u003e\n\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eQ\u003c/strong\u003e: What is Bayesian probability adding here? \u003cstrong\u003eA\u003c/strong\u003e: there are many answers, but here\u0026rsquo;s my favourite: in classical logic, an implication \\(p\\to q\\) allows information to flow from p to q. But if you know the value of q, you don\u0026rsquo;t know anything about p. The essence of Bayesian probability is precisely that if you have \\(p\\to q\\) and you know about q, you know about p. \u003cstrong\u003eInformation flows backwards\u003c/strong\u003e. That\u0026rsquo;s a pretty abstract answer, but can be made precise, albeit with more technical details added. That said, there are non-probabilistic approaches available too.\u003c/p\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003cscript\u003e\n// find all \u003cpre\u003e elements and set up the editor on them\nvar preEls = Array.prototype.slice.call(document.querySelectorAll(\"pre\"));\npreEls.map(function(el) { editor.setup(el, {language: 'webppl'}); });\n\u003c/script\u003e\n"
    },
    {
        "title" : "AI in the Library of Babel",
        "date_published" : "2018-05-03T10:42:56+02:00",
        "date_modified" : "2018-05-03T10:42:56+02:00",
        "id" : "https://reubenharry.github.io/blog/ai-in-the-library-of-babel/",
        "url" : "https://reubenharry.github.io/blog/ai-in-the-library-of-babel/",
        "content_html" : "\n\n\u003c!-- almost as ludicrous as it would be to search the gene space for organisms...(ellipsis for effect) --\u003e\n\n\u003c!-- the quest in mathematical logic to search the space of logical formulae for ones which mean true things: this is [provably](Gödel, Escher, Bach) impossible in suitably interesting settings. --\u003e\n\n\u003c!-- ``The late great evolutionary theorist Geogre Williams insisted that it was a mistake to identify genes with DNA molecules. That would be approximately the same mistake as thinking that Hamlet is made out of ink....Genes, as reciples for making proteins, are also abstract, informational things...'' Intuition pump to prove the point: digital meiosis. dennett then notes that sperm motility wouldn't be selected for here. the dangers of mut. mut. --\u003e\n\n\u003c!-- the mistake the arises from borgesification: --\u003e\n\n\u003c!-- Some people said that what science showed was that nothing was really solid, solidity was an illusion, but Eddington knew better than to go that far. Some people have said that color is an illusion. Is it? Electromagnetic radiation in the narrow range that accounts for human vision (the range in between infrared and ultraviolet) is not made of little colored things, and atoms, even gold atoms, aren't colored. But still, color is not an illusion in the sense that natters: nobody thinks Sony is lying when it says that its color televisions really show the world of color, or that Sherwin-Williams should be sued fro fraud for selling us many different colors in the form of paint. How about dollars? These days the vast majority of them aren't made of silver or even paper. They are virtual, made of information, not material, just like poems and promises. Does that mean that they are an illusion? No, but don't hunt for them anong the molecules --\u003e\n\n\u003c!-- in borges' story, there is an example of shifting context to dislodge meanings from their strings: --\u003e\n\n\u003c!-- but there's more, because this example is like in the real world but way too extreme (there's no real library) --\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;Every block of stone has a statue inside it and it is the task of the sculptor to discover it.\u0026rdquo; - Michelangelo\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eBorges inhabits a genre you could describe as ironic realism. His stories are liberally sprinkled with a trope where he takes some abstraction of his choice and makes it parochially literal in a deliberately absurd way. In the spirit of making up unwieldy words, I\u0026rsquo;ll call it:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u003cem\u003eborgesification\u003c/em\u003e: the act of taking an abstract concept literally.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eFor instance, I could imagine him writing a story in which the clearly figurative Michelangelo quote above is interpreted literally and sculptors spend their careers searching for certain blocks of stone which they think contain the desired statues. Here, Borges would be \u003cem\u003eborgesifying\u003c/em\u003e the idea of creativity as a search, on which more (not very much) later.\u003c/p\u003e\n\n\u003cp\u003eBut instead of an imaginary short story (though I\u0026rsquo;m sure Borges would appreciate that concept), I\u0026rsquo;ll give an example of borgesification in one of his actual ones, \u003cem\u003eThe Library of Babel\u003c/em\u003e. Since meaning is the intersection of artificial intelligence and linguistics that I personally care about, I can\u0026rsquo;t help extrapolating some morals from it.\u003c/p\u003e\n\n\u003ch2 id=\"the-library-of-babel\"\u003eThe Library of Babel\u003c/h2\u003e\n\n\u003cp\u003eIn Borges\u0026rsquo; short story \u003cem\u003eThe Library of Babel\u003c/em\u003e, all books exist, present in an enormous library which constitutes the known world. Every possible combination of symbols (up to some length n) seems to be present in some book somewhere.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;Everything: the minutely detailed history of the future\u0026hellip;the translation of every book in all languages\u0026hellip;the treatise that Bede could have written (and did not) about the mythology of the Saxons\u0026hellip;\u0026ldquo;.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eLibrarians search for truth by physically searching the library for the book that contains it. They spend their lives traveling through the library, occasionally stumbling on interpretable phrases.\u003c/p\u003e\n\n\u003cp\u003eThis conceit is obviously pretty absurd, but what exactly is being \u003cem\u003eborgesified\u003c/em\u003e? To answer that, a brief detour\u0026hellip;\u003c/p\u003e\n\n\u003ch2 id=\"creativity-as-search\"\u003eCreativity as Search\u003c/h2\u003e\n\n\u003cp\u003eOne of the really old ideas in AI is that creativity is just search in the appropriate search space.\u003c/p\u003e\n\n\u003cp\u003eThis applies both to problems that have an obvious search-like element (e.g. planning a route from 2 points that your roomba should take) but also creative tasks like writing a novel: there\u0026rsquo;s a space of possible ways your novel could be, and \u003cem\u003eall you have to do\u003c/em\u003e is to find the right one. Another example further afield, from Greek poet Seferis, which mirrors the Michelangelo quote above.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;all poems written or unwritten exist\u0026hellip;The special ability of the poet is to see them.\u0026rdquo;.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003e\u003cem\u003eCreativity as search\u003c/em\u003e goes hand in hand with the quest in AI (and philosophy, for that matter) to find appropriate representations.\u003c/p\u003e\n\n\u003cp\u003eFor example, consider the task of image generation from sentences. Machine learning has yielded a modicum of success at this \u003ca href=\"https://arxiv.org/abs/1804.01622\"\u003etask\u003c/a\u003e: you provide a sentence describing a scene, like:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;A sheep by another sheep standing on the grass with sky above and a boat in the ocean by a tree behind the sheep\u0026rdquo;\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eand get a picture in return. Here\u0026rsquo;s a real example generated by a computer from that sentence. Blurry but pretty amazing when you think about what the computer had to understand to do this:\u003c/p\u003e\n\n\u003cfigure \u003e\n\u003cimg src=\"/img/sheep.png\"  width=\"750\" height=\"78\"\u003e\n\u003c/figure\u003e\n\n\n\u003cp\u003eThinking about this task as a search problem, there\u0026rsquo;s a space of possible images, and the task is finding the right one for the sentence.\u003c/p\u003e\n\n\u003cp\u003eBut intuitively, it would seem crazy to consider every combination of however many pixels make up this image. Instead, we want to consider different \u003cem\u003escenes\u003c/em\u003e, which aren\u0026rsquo;t made of pixels, so much as objects and their relations.\u003c/p\u003e\n\n\u003cp\u003eIn other words, it seems like we should be searching through scene space, not pixel space. (I haven\u0026rsquo;t discussed that algorithm that actually produced the above picture - I\u0026rsquo;ll save that for another time.)\u003c/p\u003e\n\n\u003ch2 id=\"creativity-as-search-borgesified\"\u003e\u003cem\u003eCreativity as Search\u003c/em\u003e Borgesified\u003c/h2\u003e\n\n\u003cp\u003eReturning now to the story of the library, we now have the tools to describe the borgesification in more detail.\u003c/p\u003e\n\n\u003cp\u003eBorges has taken the idea that creativity is a form of search and interpreted it in the most literal way possible, so that the librarians search not the space of possible meanings, but the space of possible strings.\u003c/p\u003e\n\n\u003c!-- The fallacy inherent in this conceit is somewhat obvious, but instructive to spell out:  --\u003e\n\n\u003c!-- A string of characters is not the same as the meaning you might obtain by interpreting that string according to any particular language. (Note how Borges blurs this distinction already by referring to particular strings of characters by their interpretations, e.g. a counterfactual treatise written by Bede.) --\u003e\n\n\u003cp\u003eBecause the librarians believe that meaning \u003cem\u003einheres\u003c/em\u003e in the library\u0026rsquo;s books, they try to answer questions about the world by searching over the space of strings, rather than the space of ideas that those strings might, interpreted in some language, represent.\u003c/p\u003e\n\n\u003cp\u003eMoreover, they believe that the books \u003cem\u003emean\u003c/em\u003e things when interpreted in their language, even though there\u0026rsquo;s no reason to reject the null hypothesis that they\u0026rsquo;re just random.\u003c/p\u003e\n\n\u003c!-- Forget thinking about clever proofs - to find the answer to Fermat's last theorem, just find the book it's written in. To write the most beautiful song in the world, just pick it out from the space of possibilities. --\u003e\n\n\u003c!-- (Imputing meaning to a text seems reasonable in general: when I look at a book consisting of strings of characters, it's not weird that I learn something about the world by interpreting those characters according to the rules of English. --\u003e\n\n\u003c!-- But when that book is just one of the totality of possible combinations of symbols in an endless library, the belief that you can learn things about in any particular language ) --\u003e\n\n\u003cp\u003eThe \u003ca href=\"https://en.wiktionary.org/wiki/locus_classicus\"\u003elocus classicus\u003c/a\u003e of smart thinking about form, meaning and intelligence is Douglas Hofstadter\u0026rsquo;s \u003cem\u003eGödel, Escher, Bach\u003c/em\u003e which makes a point precisely on these lines:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;people often attribute meaning to words in themselves, without being in the slighest aware of the very complex \u0026ldquo;isomorphism\u0026rdquo; that imbues them with meanings. This is an easy enough error to make. It attributes all the meaning to the object (the word), rather than to the link between that object and the real world.\u0026ldquo;.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eIn a way, Douglas Hofstadter\u0026rsquo;s whole thesis in \u003cem\u003eGödel, Escher, Bach\u003c/em\u003e revolves around these level slips between meaning and form, construed both as a feature and a bug of cognition.\u003c/p\u003e\n\n\u003c!-- Someone sensible who lived in the library would never reject the null hypothesis that no interpretation of the library's books gives you any information about anything in the world. Borges, in typical fashion, introduces this reasonable and correct belief as the position of radicals: --\u003e\n\n\u003c!-- \u003e \"(I know of an uncouth region whose librarians repudiate the vain and superstitious custom of finding a meaning in books and equate it with that of finding a meaning in dreams or in the chaotic lines of one's palm... They admit that the inventors of this writing imitated the twenty-five natural symbols, but maintain that this application is accidental and that the books signify nothing in themselves.)\" --\u003e\n\n\u003c!-- or learning to code by memorizing muscle movements corresponding to successful programs.  --\u003e\n\n\u003cp\u003eHere\u0026rsquo;s another example of a similar borgesification, outside of Borges\u0026rsquo; writing: at one point in Lemony Snicket\u0026rsquo;s superb \u003cem\u003eA Series of Unfortunate Events\u003c/em\u003e, Klaus has to open a door by entered a passcode. He\u0026rsquo;s told this code is the sentence describing the central theme of Anna Karenina and accordingly enters the following words\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;a rural life of moral simplicity, despite its monotony, is the preferable personal narrative to a daring life of impulsive passion, which only leads to tragedy.\u0026rdquo;\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eAnd the door opens. This is absurd because you could never expect someone to enter that exact sequence given the prompt: there might be one moral of the book, but there are countless strings of words which represent that moral. In other words, there might be a unique answer in concept space, but not in string space.\u003c/p\u003e\n\n\u003cp\u003eOnly in a world where symbols were somehow inseparable from their meanings could this security system be expected to work.\u003c/p\u003e\n\n\u003ch2 id=\"the-superficial-moral\"\u003eThe superficial moral\u003c/h2\u003e\n\n\u003cp\u003eThe mistake made by Borges\u0026rsquo; librarians is one often thought to be made for real in AI systems.\u003c/p\u003e\n\n\u003cp\u003eCritics of connectionism and now more modern statistical methods for translation, image recognition, dialogue generation, chess playing and so on level that these systems, which are learnt by fitting models to huge amounts of data, aren\u0026rsquo;t engaging with meaning. Or to put it another way, they don\u0026rsquo;t incorporate the right sort of representation. (Criticisms of this nature date back at least to the push back against behaviorism in both cognitive science and AI - see Marr\u0026rsquo;s levels, Chomsky\u0026rsquo;s performance-competence distinction).\u003c/p\u003e\n\n\u003cp\u003eThis perceived intensional failing is usually translated into an extensional prediction: that AI needs something more to pass the Turing test.\u003c/p\u003e\n\n\u003cp\u003eFor instance, \u003ca href=\"http://rocknrollnerd.github.io/ml/2015/05/27/leopard-sofa.html\"\u003ethis well-known article\u003c/a\u003e nicely illustrates a failure mode of statistical image recognition where a leopard skin couch is recognized as a leopard. The problem seems to be that the decision process for leopard-hood used by the statistical classifier has no abstract representation of 3D shape.\u003c/p\u003e\n\n\u003cp\u003eAnother example is \u003ca href=\"https://en.wikipedia.org/wiki/Winograd_Schema_Challenge\"\u003eWinograd schemas\u003c/a\u003e, on which front I\u0026rsquo;ll defer to wikipedia, pointing out just that the pattern is the same: there\u0026rsquo;s a claimed extensional failing of systems that don\u0026rsquo;t \u0026ldquo;understand\u0026rdquo; language from a perceived intensional failing: lack of a semantics.\u003c/p\u003e\n\n\u003cp\u003eSo you might be tempted to agree with the following version of Klaus from one of the library of Babel\u0026rsquo;s variations on \u003cem\u003eA Series of Unfortunate Events\u003c/em\u003e:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003eKlaus: the moral of \u003cem\u003eThe Library of Babel\u003c/em\u003e is that an algorithm which doesn\u0026rsquo;t take into account the appropriate representations for the task in question is doomed to failure.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003c!-- Just in the same way that the librarians think randomly chosen strings of symbols are about history or their lives, I like to think The Library of Babel is really about AI.\n --\u003e\n\n\u003c!-- A perennial criticism first of [connectionism]( link) and now of modern statistical AI as used in machine translation, is that it does not engage with the correct level of abstraction, namely the *meanings* of the sentences it translates. --\u003e\n\n\u003c!-- For instance, critics regularly complain that neural machine translation systems don't manipulate representations of syntactic or semantic structure and as such, are just a sort of data-driven hack. --\u003e\n\n\u003c!-- The alternative they imagine is that the system first translates the target sentence into an abstract meaning, maybe represented in first order logic, and then back out again into another language. --\u003e\n\n\u003c!-- then doing some finagling AT THIS LEVEL OF ABSTRACTION --\u003e\n\n\u003c!-- A word for this, coined by Douglas Hofstadter (the second neologism, as promised) is sphexishness. This describes the \"algorithm\" of the Sphex wasp when preparing food for its young. In short, \"the wasp's routine is to bring the paralyzed cricket to the burrow, leave it on the threshold, go inside to see that all is well, emerge, and then drag the cricket in. If the cricket is moved a few inches away while the wasp is inside making her preliminary inspection, the wasp, on emerging from the burrow, will bring the cricket back to the threshold, but not inside, and will then repeat the preparatory procedure of entering the burrow to see that everything is all right.\" -(*Gödel, Escher, Bach*). --\u003e\n\n\u003c!-- Although subsequently the biological facts have turned out to be more nuanced, the original example is still useful. The point is that the wasp's algorithm works just fine in normal circumstances, but needlessly repeats the burrow-checking step when one element of its routine is altered. It doesn't really understand the meaning of its actions, because if it did, it would act differently. In other words, *this extensional failing is taken to indicate an intensional problem with the wasp's algorithm*. --\u003e\n\n\u003c!-- *Sphexish* is the perfect word to describe the librarians' method of answering questions about the world. And machine learning, according to some, has the same failing: it works in a certain subset of cases, but by dint of not engaging with meaning, will fail - it's claimed - when meaning is required. A standard example is a Winograd schema: --\u003e\n\n\u003c!-- in order to translate this correctly, you have to identify which group \"they\" refers to, which requires you to know that --\u003e\n\n\u003c!-- It's worth pointing out that Winograd schemas aren't exactly the Achilles' heel they're posed as for neural machine translation - for instance, see  LINK --\u003e\n\n\u003c!-- but it's easy to sympathise with the critics: it just *seems wrong* to not engage with the appropriate abstractions in favour of training systems on swathes of inherently meaningless data, like books in the library of Babel. --\u003e\n\n\u003ch3 id=\"that-said\"\u003eThat said.\u003c/h3\u003e\n\n\u003cp\u003eI think you\u0026rsquo;d be wrong to agree with this version of Klaus. Nor indeed do I think the above is a good moral as regards modern statistical AI.\u003c/p\u003e\n\n\u003cp\u003eI can\u0026rsquo;t really do justice to why I think that without a much longer digression, but the general gist of it is that representations and/or meanings in cognition aren\u0026rsquo;t at all what they seem. Form and meaning are weirdly inextricable.\u003c/p\u003e\n\n\u003cp\u003eThis is a sentiment that you can definitely feel in \u003cem\u003eGödel, Escher, Bach\u003c/em\u003e (although Douglas Hofstadter definitely isn\u0026rsquo;t a proponent of modern machine translation) and in bits and pieces of philosophy from Hume to Quine.\u003c/p\u003e\n\n\u003cp\u003eIf I had to improve on Klaus\u0026rsquo; moral of the \u003cem\u003eLibrary of Babel\u003c/em\u003e, he would utter something a bit more long winded:\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003emeaning is never a property of objects independent of their contexts, no matter how strongly it might seem to be, and if we assume it is, we will end up trying to build impossible systems which attempt to explicitly represent concepts which in truth should be merely \u003cem\u003eexplanations\u003c/em\u003e of these systems.\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003ch2 id=\"some-caveats-and-endnotes\"\u003eSome caveats and endnotes:\u003c/h2\u003e\n\n\u003col\u003e\n\u003cli\u003eI\u0026rsquo;ve been using \u0026ldquo;meaning\u0026rdquo;, \u0026ldquo;intension\u0026rdquo;, \u0026ldquo;abstraction\u0026rdquo; and \u0026ldquo;representation\u0026rdquo; somewhat interchangeably. I\u0026rsquo;m of the mind that these are words approximating the same idea, just from different perspectives, but of course, in particular technical contexts that\u0026rsquo;s not always true.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003c!-- I don't think it's a good moral because the problem with the librarians is not that they're sphexish. In fact, I don't think sphexishness is a problem at all. --\u003e\n\n\u003c!-- Their problem is that they are committed to the misguided assumption that meaning is a thing books just *have*, rather than a thing books have in the context of an interpretation. --\u003e\n\n\u003col\u003e\n\u003cli\u003eYou might wonder, reading this slightly weird hagiography of Borges, whether I really believe his stories are \u003cem\u003eabout\u003c/em\u003e intensionality and meaning. Avoiding the obvious answer that \u003cem\u003eThe Library of Babel\u003c/em\u003e exists to problematize aboutness (i.e. intensionality, i.e. meaning), I think this is an emphatic yes. I also think they demonstrate how effective it is to do philosophy by parable, a moral which philosophers like Daniel Dennett have taken up with aplomb.\u003c/li\u003e\n\u003c/ol\u003e\n\n\u003c!-- # Borgesification Elsewhere --\u003e\n\n\u003c!-- Borgesification is everywhere in Borges. Another story, **Pierre Menard, Author of the Quixote** is a borgesification of the idea that writing is just a changing of the context of a previous text. *Funes the Memorious*  CHECK is a borgesification of  --\u003e\n\n\u003c!-- MAYBE DROP ALL OF THE SECOND ONE\nPhilosophical Idea 2: Pierre Menard\n\ncreativity is recontextualisation\n\nAI spin?? :\n\n(when you're unsure what to do, remember this as your destination: borges' idea of inventing an author/meaning is like a virtual object, and all objects are virtual. make the connection abundantly clear)\n\nPostmodern strains of thought often take interest\n    in the notion that the meaning of texts (writ broad)\n        are not fixed in the texts themselves, but are continually recreated by succesive authors' usage of those texts\n\n        Thus two authors can express the same idea but have it be understood differently...??\n\n        also: forms are necessary\n    or: none of the meaning is natural to the text itself\nor more precisely: texts that are conceptually the same can differ by context NOT QUITE\nthe idea that writing is really just recontextualisation of past texts:\nfor example, Catullus writes a poem\n    remarkably similar to:\n        ...\n        is this good example?\n\nThis radical idea builds on the difficulty in separating the meaning of a text from the process of interpretation.\n    to what degree is blah Blah and to what degree is its blahness a result of our interpretation\n\n    most radical: nothing in text at all\n\n\n\nBorgesification:\n\nFinally my favourite.\n\nstory: pierre menard...\n\nPierre Menard is a poet totally devoted to creating original work, but his magnum opus is a word for word copy of Don Quixote.\n    Borges goes into great detail pointing about how...\n\n    quotes:\n\n        The Cervantes text and the Menard text are verbally identical, but the second is almost infinitely richer. `..truth, whose mother is hostiry, rival of time, depository of deeds...\": written by the \"ingenious layman\" miguel de Cervantes, is mere rhetorical praise of history, [but for menard]: History, the mother of truth! - the idea is straggering. Menard, a contemporary of William James, defines history not as a delving into reality but as the ery fount of reality.The contrast in styles...\n\nAH: (quix X context1) vs (quix X context2): tensor product\n\n\npoint here:\nI'm also thinking of his imagined poet, Pierre Menard, who copies Don Quixote word for word, in order to produce an entirely original text.\n\nin this case, the philosophical point in the background is that\n\n\nbut which are only fantasy by virtue of taking a philosophical idea to an overliteral extreme:\n\n\nhe even admits it: fantasy quote\n\nBorgesification without Borges:\n\nBorgesification is pretty ubiquitous\nboth as a technique in literature\nand a genuine fallacy in philosophy\n\nfor the former,\n    in one of many excellent Series of Unfortunate Events (surely the most postmodern children's books ever written), there is a door that can only be unlocked by entering on a keyboard the central theme of Anaa Karenina\n        this, is \"is that a rural life of moral simplicity, despite its monotony, is the preferable personal narrative to a daring life of impulsive passion, which only leads to tragedy.\"\n\n    This is a borgesification, because while Anna Karenina might indeed have a central theme, the premise of this situation is that the precise wording Klaus provides is somehow\n        is that the door requires to be provided a particular point in the sentence space, not the idea space\n\n    precise wording is surely not derivable\n\n        search space of ideas: choose idea\n        requires: search space of words\n\nThis sort of confusion between high level ideas (like\n) and low level ones is\n\nfor the latter, I think that the view that free will has anything to do with the physical world's being determined or not, is really a fallacy of borgesification\n\n\nOvid loves borgesification.\nEXAMPLE:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"The idealists argue that the hexagonal rooms are a necessary form of absolute space or, at least, of our intuition of space. They reason that a triangular or pentagonal room is inconceivable.\"\n\n\"(I know of an uncouth region whose librarians repudiate the vain and superstitious custom of finding a meaning in books and equate it with that of finding a meaning in dreams or in the chaotic lines of one’s palm . . . They admit that the inventors of this writing imitated the twenty-five natural symbols, but maintain that this application is accidental and that the books signify nothing in themselves. This dictum, we shall see, is not entirely fallacious.)\"\n\n\"From these two incontrovertible premises he deduced that the Library is total and that its shelves register all the possible combinations of the twenty-odd orthographical symbols (a number which, though extremely vast, is not infinite) that is, everything it is given to express: in all languages. Everything: the minutely detailed history of the future, the archangels’ autobiographies, the faithful catalogues of the Library, thousands and thousands of false catalogues, the demonstration of the fallacy of those catalogues, the demonstration of the fallacy of the true catalogue, the Gnostic gospel of Basilides, the commentary on that gospel, the commentary on the commentary on that gospel, the true story of your death, the translation of every book in all languages, the interpolations of every book in all books, the treatise that Bede could have written (and did not) about the mythology of the Saxons, the lost works of Tacitus.\"\n\n\"When it was proclaimed that the Library contained all books, the first impression was one of extravagant happiness. All men felt themselves to be the masters of an intact and secret treasure. There was no personal or world problem whose eloquent solution did not exist in some hexagon. The universe was justified, the universe suddenly usurped the unlimited dimensions of hope. At that time a great deal was said about the Vindications: books of apology and prophecy which vindicated for all time the acts of every man in the universe and retained prodigious arcana for his future. Thousands of the greedy abandoned their sweet native hexagons and rushed up the stairways, urged on by the vain intention of finding their Vindication. \"\n\ninformation theoretic point that if everything is meaningful, nothing is meaningful\n\npossible worlds semantics\ntextual variants: how do you represent a book?\n\nbasically the question of deciding whether there is an intentional author\n\ndennett and questions of semantics:\n --\u003e\n"
    },
    {
        "title" : "Medieval Type Theory",
        "date_published" : "2017-06-22T21:33:50+01:00",
        "date_modified" : "2017-06-22T21:33:50+01:00",
        "id" : "https://reubenharry.github.io/blog/medieval-type-theory/",
        "url" : "https://reubenharry.github.io/blog/medieval-type-theory/",
        "content_html" : "\u003cp\u003eThis post definitely falls under philosophical miscellanea, but is a nice example of a commonality between ancient and modern philosophy.\u003c/p\u003e\n\n\u003cp\u003eSextus Empiricus, medieval skeptic, wrote a big (not Aquinas big, but definitely David Foster Wallace big) treatise on Pyrrhonism, a brand of radical skepticism which argues (more or less) that nothing is knowable. More specifically, Empiricus - aptly or inaptly named, I\u0026rsquo;m not sure - rejects \u003cem\u003edogma\u003c/em\u003e (roughly, scientific knowledge).\u003c/p\u003e\n\n\u003cp\u003eThis runs into hot or at least lukewarm water soon enough, since, as the Pyrrhonists are quick to realise, that for P = \u0026ldquo;Dogma is unknowable.\u0026rdquo;, if one knows it, it\u0026rsquo;s false, thus refuting the whole thesis.\u003c/p\u003e\n\n\u003cp\u003eEmpiricus\u0026rsquo; solution is to offer two notions of dogma: narrow and broad. One must reject narrow dogma, but the rejection of narrow dogma (i.e. P=\u0026ldquo;Narrow dogma is unknowable.\u0026rdquo;) is a broad dogma, and that\u0026rsquo;s totally fine to keep.\u003c/p\u003e\n\n\u003cp\u003eJump to Russell, and his famous paradox as to whether to set of all sets that don\u0026rsquo;t contain themselves contains itself. One solution, Russell\u0026rsquo;s, is to have a hierarchy of types. Type 1 sets can\u0026rsquo;t contain type 1 sets, but type 2 sets can (and so on for type 3 containing 2, etc). This eliminates the paradox.\u003c/p\u003e\n\n\u003cp\u003eEmpiricus\u0026rsquo; solution to self-refutation is Russell\u0026rsquo;s solution to Russell\u0026rsquo;s paradox, \u003cem\u003emutatis mutandis\u003c/em\u003e. Granted, you have to \u003cem\u003emutatis\u003c/em\u003e a little bit of \u003cem\u003emutandis\u003c/em\u003e, but underlyingly, it\u0026rsquo;s the same self-refuting paradox and the same type-based solution.\u003c/p\u003e\n\n\u003cp\u003eIn actual fact, Empiricus doesn\u0026rsquo;t just give this one solution, but in a manner typical of rambling ancient philosophers, throws in a whole bunch to see what sticks, including the idea that the contradiction inherent in knowing that everything is unknowable is actually okay, and is like taking an emetic which purges the system. Nice and graphic.\u003c/p\u003e\n"
    },
    {
        "title" : "Proofs, Refutations and Zombies",
        "date_published" : "2016-08-20T15:10:55-04:00",
        "date_modified" : "2016-08-20T15:10:55-04:00",
        "id" : "https://reubenharry.github.io/blog/proofs-refutations-and-zombies/",
        "url" : "https://reubenharry.github.io/blog/proofs-refutations-and-zombies/",
        "content_html" : "\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;There is strictly speaking no such thing as mathematical proof; we can, in the last analysis, do nothing but point; \u0026hellip;proofs are rhetorical flourishes designed to affect psychology\u0026rdquo; - Hardy\u003c/p\u003e\n\n\u003cp\u003e\u0026ldquo;Other thought experiments are less rigorous but often just as effective: little stories designed to provoke a heartfelt, table thumping intuition - \u0026ldquo;Yes of course, it has to be so\u0026rdquo; - about whatever thesis is being defended\u0026rdquo; - Dennett\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eSomewhat inspired by Jacob Andreas\u0026rsquo; note-form \u003ca href=\"http://blog.jacobandreas.net/translation-meaning.html\"\u003eposts on philosophers\u003c/a\u003e, I wanted to jot down what I\u0026rsquo;m taking away from reading Lakatos\u0026rsquo; \u003cem\u003eProof and Refutation\u003c/em\u003e (the above title being a reference not just to \u003ca href=\"https://www.amazon.com/Pride-Prejudice-Zombies-Quirk-Classic/dp/1511336188\"\u003ethis\u003c/a\u003e, but also to \u003ca href=\"https://en.wikipedia.org/wiki/Philosophical_zombie\"\u003ephilosophical zombies\u003c/a\u003e which are humans extensionally but not intensionally. Lakatos explores the equally tricky, and I think closely related issue of the extensional and intensional notions of proof, though not in those words.)\u003c/p\u003e\n\n\u003cp\u003eThe book is noteworthy in two ways: first, it convincingly points out that the default conception of mathematical proofs as well-defined formal objects doesn\u0026rsquo;t at all capture the notion of proof as used, which is more like a way of thinking about a problem. Lakatos pushes this point to the extent of saying that a proof can fail to prove what it sets out to and still be a proof - in fact, from his perspective, establishing truth is not the point; proofs exist to establish structure.\u003c/p\u003e\n\n\u003cp\u003eThe book is also noteworthy in its dialectic style; the argument is set up as a dialogue between a teacher and a classroom-full of students, and their discussion parallels the dialogues that took place over the course of mathematical history, as explained in the footnotes.\u003c/p\u003e\n\n\u003c!-- I read it through the lens of my own anti-representationalist sensibilities --\u003e\n\n\u003cp\u003eLakatos does an amazing job of diving into the mathematical detail, while staying intelligible (inevitably, half of the effort in teaching is finding just the right sort of examples for a good exposition of an idea).\u003c/p\u003e\n\n\u003cp\u003eThe following are basically just chapter-by-chapter notes on the book - nothing particularly synthesized - so this will expand as and when I move through the rest of the book.\u003c/p\u003e\n\n\u003ch1 id=\"chapter-1\"\u003eChapter 1\u003c/h1\u003e\n\n\u003cp\u003eThis chapter seems to constitute a sort of Socratic attack on the \u0026ldquo;dogma\u0026rdquo; that proofs are mathematical or logical objects.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;Many working mathematicians are puzzled about what proofs are for if they do not prove. On the one hand, they know from experience that proofs are fallible but on the other hand they know from their dogmatist indoctrination that \u003cem\u003egenuine\u003c/em\u003e proofs must be infallible. \u003cem\u003eApplied mathematicians\u003c/em\u003e usually solve this dilemma by a shamefaced but firm belief that the proof of the \u003cem\u003epure mathematicians\u003c/em\u003e are \u0026lsquo;complete\u0026rsquo;, and so \u003cem\u003ereally\u003c/em\u003e prove. Pure mathematicians, however, know better - they have such respect only for the \u0026lsquo;complete proofs\u0026rsquo; for \u003cem\u003elogicians\u003c/em\u003e. If asked what is then the use, the function, of their \u0026lsquo;incomplete\u0026rsquo; proofs\u0026rsquo;, most of them are at a loss.\u0026rdquo;\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eLakatos exemplifies this point by careful examination of Euler\u0026rsquo;s formula (V−E+F=2). As shown in a series of careful proofs and refutations of the claim that polyhedra\u0026rsquo;s vertices (V), edges (E) and faces (F) obey V-E+F=2, it\u0026rsquo;s hard to nail down what exactly what a particular proof is a proof of.\u003c/p\u003e\n\n\u003cp\u003eGiven a counterexample to V−E+F=2 in the form of a weird looking polyhedron, one student\u0026rsquo;s response is \u003cem\u003emonster-barring\u003c/em\u003e: ruling that this counterexample isn\u0026rsquo;t a \u003cem\u003ereal\u003c/em\u003e polyhedron in the sense meant by the proof.\u003c/p\u003e\n\n\u003cp\u003eOn the one hand, this move is clearly unfalsifiable, but on the other, reflects the intuition that the counterexample misses the essence of the proof.\u003c/p\u003e\n\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;Delta\u0026rsquo;s main mistake is perhaps his dogmatist bias in the interpretation of mathematical proof: he thinks that a proof necessarily proves what it has set out to prove. My interpretation of proof will allow for a \u003cem\u003efalse\u003c/em\u003e conjecture to be \u0026ldquo;proved\u0026rdquo; .\u0026rdquo;\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eLakatos moves towards a technique where, rather than monster-barring, one identifies which lemmas in the proof lead to the failure (this can be subtle), and change those steps so that the core nature of the proof remains intact.\u003c/p\u003e\n\n\u003ch3 id=\"proof-as-explanation\"\u003eProof as Explanation\u003c/h3\u003e\n\n\u003cp\u003eAs Lakatos sees it (here I\u0026rsquo;m making the assumption that his position is represented by the teacher), a proof is not about truth, but rather, is the insight allowing a problem to be deconstructed into a particular set of lemmas. In this sense, a proof is more like an explanation.\u003c/p\u003e\n\n\u003cp\u003eWhen the \u003ca href=\"https://en.wikipedia.org/wiki/Four_color_theorem\"\u003efour colour theorem\u003c/a\u003e was proven, many mathematicians were disappointed by the nature of the proof (in large part just a brute force case by case proof done by a computer) because it didn\u0026rsquo;t afford any insight. It\u0026rsquo;s interesting to compare this to the disappointment of traditional AI researchers in machine learning methods for tasks like translation, which perform their task without giving insight into any sort of internal process involved.\u003c/p\u003e\n\n\u003cp\u003eThis raises a natural connection to algorithms and the notion of modularity:\n(there\u0026rsquo;s a much more precise connection between algorithms and proofs stemming from the Curry-Howard correspondence - this is more like an informal side note to that.). Thinking about traditional approaches to cognition (e.g. Marr), a key idea is that the mind performs computations which can be understood by identifying their subparts. (Early efforts in AI reflect a now naive seeming optimism about the degree of modularity). Likewise for Lakatos, proofs break problems down into lemmas (of which counterexamples may refute all or only part).\u003c/p\u003e\n\n\u003cp\u003eAnd the skepticism Lakatos has about proofs as formal objects reminds me of Dennett\u0026rsquo;s skepticism about intentions, among other things: regarding a chess playing computer, we may say things like \u0026ldquo;it\u0026rsquo;s trying to get the queen out; that\u0026rsquo;s why it made that move\u0026rdquo;. This is a modularization of its strategy, breaking it into two (further sub-dividable) lemmas (first: get queen out, then: win).\u003c/p\u003e\n\n\u003cp\u003eOn the Dennettian view (at least based on my scant reading) the chess player\u0026rsquo;s algorithm is fundamentally an explanatory concept (with a complex connection to the actual program), just as a proof of a proposition is an explanation (with a complex connection to the \u003cem\u003eformal\u003c/em\u003e proof of the proposition), not a guarantee of truth.\u003c/p\u003e\n\n\u003cp\u003eI also wonder if proofs can be both formal and explanatory. I\u0026rsquo;m thinking particularly of diagrammatic proofs, as have become popular for category theory - this excellent series of blog posts is one example: \u003ca href=\"https://graphicallinearalgebra.net/\"\u003ehttps://graphicallinearalgebra.net/\u003c/a\u003e\u003c/p\u003e\n\n\u003ch3 id=\"other\"\u003eOther\u003c/h3\u003e\n\n\u003cp\u003eHidden in the footnotes, there are references to Skepticism; Lakatos cites \u003ca href=\"https://reubenharry.github.io/blog/medieval-type-theory/\"\u003eSextus Empiricus\u003c/a\u003e, for example, and frequently uses the term \u003cem\u003edogmatist\u003c/em\u003e which I assume he gets from Empiricus too.\u003c/p\u003e\n"
    },
    {
        "title" : "Informativity and Galois Connections",
        "date_published" : "2015-06-26T17:07:24+01:00",
        "date_modified" : "2015-06-26T17:07:24+01:00",
        "id" : "https://reubenharry.github.io/blog/informativity-and-galois-connections/",
        "url" : "https://reubenharry.github.io/blog/informativity-and-galois-connections/",
        "content_html" : "\n\n\u003cscript type=\"text/javascript\" async\n  src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML\"\u003e\n\u003c/script\u003e\n\n\u003cp\u003eHere is an elementary observation (I mean \u0026ldquo;elementary\u0026rdquo; in the sense mathematicians sometimes use it: i.e. straightforward if you already understand it, otherwise gibberish) that I talked about at MIT\u0026rsquo;s \u003ca href=\"http://brendanfong.com/seminar.html\"\u003ecategory theory seminar\u003c/a\u003e, relating \u003ca href=\"http://www.glottopedia.org/index.php/Gricean_maxims\"\u003eGrice\u0026rsquo;s maxims of Quantity and Quality\u003c/a\u003e to the mathematical notion of a Galois connection.\u003c/p\u003e\n\n\u003ch3 id=\"inscrutable-summary\"\u003eInscrutable Summary:\u003c/h3\u003e\n\n\u003cp\u003eFor a state space W, the left adjoint of a monotone map (i.e. a left Galois connection), \\(L_0\\), from a set of utterances U to the poset (ordered by inclusion) \\(\\mathcal{P}(W)\\) is the monotone map \\(S_1: \\mathcal{P}(W)\\to U\\) which takes a set of states and returns the strongest true utterance with respect to \\(L_0\\). This happens to be a very natural way to encode Grice\u0026rsquo;s maxims of Quality (roughly: speak truthfully) and Quantity (roughly: be as informative as possible, relative to what is relevant) simultaneously.\u003c/p\u003e\n\n\u003ch3 id=\"scrutable-explanation\"\u003eScrutable Explanation:\u003c/h3\u003e\n\n\u003cp\u003eEach \\(w \\in W\\) is a state of the world, or, so that each element of \\(\\mathcal{P}(W)\\) is a set of states.\u003c/p\u003e\n\n\u003cp\u003eAs usual, the simplest possible example is a reference game, where \u0026ldquo;state\u0026rdquo; just means the intended referent. Concretely, say that W = \\(\\{R_1, R_2, R_3\\}\\) as pictured below, and U = {\u003cem\u003ered dress\u003c/em\u003e, \u003cem\u003edress\u003c/em\u003e, \u003cem\u003ehat\u003c/em\u003e, \u003cem\u003esilence\u003c/em\u003e}. Obviously arbitrary choices, but just for illustration.\u003c/p\u003e\n\n\u003cfigure \u003e\n\u003cimg src=\"/img/referents.png\"  width=\"747\" height=\"297\"\u003e\n\u003c/figure\u003e\n\n\n\u003cp\u003eSay that the literal listener \\(L_0\\) maps an utterance \u003cem\u003eu\u003c/em\u003e to the set of referents (i.e. states, i.e. worlds) compatible with \u003cem\u003eu\u003c/em\u003e, mapping \u003cem\u003ered dress\u003c/em\u003e to \\(\\{R_1\\}\\), \u003cem\u003edress\u003c/em\u003e to \\(\\{R_1, R_2\\}\\) , \u003cem\u003ehat\u003c/em\u003e to \\(\\{R_3\\}\\) and \u003cem\u003esilence\u003c/em\u003e to \\(\\{R_1, R_2, R_3\\}\\).\u003c/p\u003e\n\n\u003cp\u003eNote that we can make U a poset by defining the partial ordering on U where \\(u \\leq u\u0026rsquo; \\leftrightarrow L_0(u) \\leq L_0(u\u0026rsquo;)\\). For example, \\(\\mathit{dress} \\leq \\mathit{silence}\\). Note that \\(u \\leq u\u0026rsquo;\\) means that u is \u003cem\u003estronger\u003c/em\u003e than u\u0026rsquo;.\u003c/p\u003e\n\n\u003cp\u003eIt then follows (by the definition of the ordering on U) that \\(L_0\\) is a monotone map (i.e. a function that preserves the poset ordering) from U to W.\u003c/p\u003e\n\n\u003ch3 id=\"galois-connections\"\u003eGalois Connections\u003c/h3\u003e\n\n\u003c!-- The idea of a Galois connection (I think invented by Galois in his proof that there's no general formula for quintic equations) --\u003e\n\n\u003cp\u003eSo far just definitions. Just one more: for monotone maps f and g, f is the left Galois connection of g iff:\u003c/p\u003e\n\n\u003cp\u003e$$f(s) \\leq u \\leftrightarrow s \\leq g(u)$$\u003c/p\u003e\n\n\u003cp\u003eIt takes a bit of thinking to make sense of this strange definition, but the intuition is this: there\u0026rsquo;s no obvious notion of an exact inverse of g, because g might well not be surjective (or injective). But for a monotone map, there\u0026rsquo;s a notion of the best approximation of such an inverse. That approximation is f, as defined above. (In fact there are two, the left and right Galois connections, and more broadly, the left and right adjoints of a functor. A monotone map is a very simple case of a functor between very simple categories, namely posets).\u003c/p\u003e\n\n\u003cp\u003eMaybe this direct corollary of the above definition will help: if I know g, then its left adjoint f is defined as:\u003c/p\u003e\n\n\u003cp\u003e$$f(s) = \\bigwedge(\\{u : s \\leq g(u)\\})$$.\u003c/p\u003e\n\n\u003cp\u003eI write \\(\\bigwedge(X)\\) for a poset X to mean the greatest lower bound of X.\u003c/p\u003e\n\n\u003cp\u003eOK, so now you can ask: what\u0026rsquo;s the left Galois connection of the literal listener \\(L_0\\)? Let\u0026rsquo;s call this left Galois connection \\(S_1\\), for reasons that will soon be clear. Again, note that \\(L_0\\) can\u0026rsquo;t just be inverted, because it\u0026rsquo;s in general not the case that for any subset s of W (i.e. element of \\(\\mathcal{P}(W)\\)), there\u0026rsquo;s an expression which means exactly s under \\(L_0\\).\u003c/p\u003e\n\n\u003cp\u003eIt\u0026rsquo;s illustrative to work through an example, to see what \\(S_1\\) looks like. Using our case from above, what\u0026rsquo;s \\(S_1(\\{R_2\\})\\)?\u003c/p\u003e\n\n\u003cp\u003eWell, \\(S_1(\\{R_2\\}) = \\bigwedge\\{u : \\{R_2\\} \\leq L_0(u)\\})\\) = \\(\\bigwedge(\\{dress, silence\\})\\) = \\(dress\\).\u003c/p\u003e\n\n\u003cp\u003eFirst you find all the utterances that map to supersets of \\(\\{R_2\\}\\). These are all the true utterances (\u003cem\u003eQuality\u003c/em\u003e). Then you take the greatest lower bound (\u003cem\u003eQuantity\u003c/em\u003e).\u003c/p\u003e\n\n\u003cp\u003eSo in other words, the definition of an left Galois connection gives you the following informative speaker \\(S_1\\): consider the set of all utterances compatible with your (possibly singleton) set of worlds, and choose the strongest of these. There\u0026rsquo;s something nice about how the maxims of Quality and Quantity fall out from this.\u003c/p\u003e\n\n\u003c!-- That's \\\\(\\\\{dress, silence\\\\}\\\\). Then you take the greatest lower bound.  --\u003e\n\n\u003c!-- The notion of \"Galois connection\" formalizes \"best approximation of the inverse of a monotone map between posets\". (More abstractly, a Galois connection is a kind of adjoint functor, but that's by the by.) --\u003e\n\n\u003cp\u003eWe also obtain similar results for pragmatic implicatures (that I won\u0026rsquo;t sketch out here for reasons of laziness) namely that a literal speaker, in the form of a monotone map \\(S_0\\) from w \\(\\in\\) W to \u003cem\u003eus\u003c/em\u003e in \\(\\mathcal{P}(U)\\), admits a left Galois connection \\(L_1\\) which returns the exhaustification (linguistics term) of the literal meaning of \u003cem\u003eus\u003c/em\u003e. So this would model, for example, the fact that the pragmatic interpretation of a (possibly singleton) set of utterances \u003cem\u003eus\u003c/em\u003e should give the smallest set of possible worlds that could have produced every \\(u \\in \\mathit{us}\\).\u003c/p\u003e\n\n\u003cp\u003eThe niceness of this correspondence between Galois connections and pragmatics suggests that something relatively deep is going on here, but I haven\u0026rsquo;t thought about it too much further. The sensible thing to do would be to consider the categorical generalization of Galois connections, namely adjoint functors, and to see if we get the same effect when we invert a more sophisticated functorial semantics.\u003c/p\u003e\n\n\u003cp\u003eI came up with this idea thanks to John Baez\u0026rsquo;s fantastic \u003ca href=\"https://forum.azimuthproject.org/categories/applied-category-theory-course\"\u003ecategory theory course\u003c/a\u003e, based off of David Spivak and Brendan Fong\u0026rsquo;s \u003cem\u003e\u003ca href=\"http://math.mit.edu/~dspivak/teaching/sp18/7Sketches.pdf\"\u003eSeven Sketches in Compositionality\u003c/a\u003e\u003c/em\u003e.\u003c/p\u003e\n\n\u003cp\u003eSummary:\u003c/p\u003e\n\n\u003cp\u003e*An informative speaker is a left Galois connection to a literal listener\u003c/p\u003e\n\n\u003cp\u003e*A pragmatic listener is a left Galois connection to a literal speaker\u003c/p\u003e\n"
    }
    ]
}
